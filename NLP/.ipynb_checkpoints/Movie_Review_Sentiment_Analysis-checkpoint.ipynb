{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f13c54-111c-443e-84a4-03a9b0d382dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf9e068-2813-4012-b820-05ed172ab8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    \"./train.tsv.zip\",\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa5069c-fdc1-483e-8ab3-f364a7aec496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89174bc5-c93c-4398-a5a0-aa6df5bacbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    \"./test.tsv.zip\",\n",
    "    sep=\"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2899cea-9d85-4871-a237-e80e98e4f16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d72ab9f-937c-4268-88a4-9db18ac47dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0a60a6-79a5-4fbe-bb76-cb6f7cd4a75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b74625-ac8e-48d4-88b3-517dd54e0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec4022f-4cbe-45ac-9fd2-0be47e902717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    text = text.lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876eb59b-1c16-4de9-975f-56361b7a15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_single_text(text):\n",
    "    \"\"\"对单个清洗后的文本进行分词\"\"\"\n",
    "    if text == \"\":  # 处理空文本\n",
    "        return []\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7982a47-e1c4-40ef-96b0-dc38a9c8d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 先清洗文本列\n",
    "train_df['Phrase_clean'] = train_df['Phrase'].apply(clean_text)\n",
    "# 2. 对清洗后的文本列批量分词\n",
    "train_df['Phrase_tokens'] = train_df['Phrase_clean'].apply(tokenize_single_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0742be1f-6bae-4c76-b53f-580ac89762a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1行原始文本：A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .\n",
      "第1行分词结果：['a', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose', 'is', 'also', 'good', 'for', 'the', 'gander', 'some', 'of', 'which', 'occasionally', 'amuses', 'but', 'none', 'of', 'which', 'amounts', 'to', 'much', 'of', 'a', 'story']\n",
      "\n",
      "第2行原始文本：A series of escapades demonstrating the adage that what is good for the goose\n",
      "第2行分词结果：['a', 'series', 'of', 'escapades', 'demonstrating', 'the', 'adage', 'that', 'what', 'is', 'good', 'for', 'the', 'goose']\n",
      "\n",
      "第3行原始文本：A series\n",
      "第3行分词结果：['a', 'series']\n",
      "\n",
      "第4行原始文本：A\n",
      "第4行分词结果：['a']\n",
      "\n",
      "第5行原始文本：series\n",
      "第5行分词结果：['series']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    print(f\"第{idx+1}行原始文本：{train_df.loc[idx, 'Phrase']}\")\n",
    "    print(f\"第{idx+1}行分词结果：{train_df.loc[idx, 'Phrase_tokens']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2eea8e-da1d-451a-a8ad-81a6e7e97c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa91d4e7-0432-4f3a-98be-1cd7a830ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff557d3f-790f-4fb8-8c73-3d742d7db5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_clean</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "      <td>[a, series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>[a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>hearst s</td>\n",
       "      <td>[hearst, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>[avuncular]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>chortles</td>\n",
       "      <td>[chortles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "                                             Phrase_clean  \\\n",
       "0       a series of escapades demonstrating the adage ...   \n",
       "1       a series of escapades demonstrating the adage ...   \n",
       "2                                                a series   \n",
       "3                                                       a   \n",
       "4                                                  series   \n",
       "...                                                   ...   \n",
       "156055                                           hearst s   \n",
       "156056                          forced avuncular chortles   \n",
       "156057                                 avuncular chortles   \n",
       "156058                                          avuncular   \n",
       "156059                                           chortles   \n",
       "\n",
       "                                            Phrase_tokens  \n",
       "0       [a, series, of, escapades, demonstrating, the,...  \n",
       "1       [a, series, of, escapades, demonstrating, the,...  \n",
       "2                                             [a, series]  \n",
       "3                                                     [a]  \n",
       "4                                                [series]  \n",
       "...                                                   ...  \n",
       "156055                                        [hearst, s]  \n",
       "156056                      [forced, avuncular, chortles]  \n",
       "156057                              [avuncular, chortles]  \n",
       "156058                                        [avuncular]  \n",
       "156059                                         [chortles]  \n",
       "\n",
       "[156060 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5255d1a-f19d-47c6-9088-4c99dd34c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_tokens(tokens):\n",
    "    filter_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            filter_tokens.append(token)\n",
    "    return filter_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9e42dc-2609-49cc-a218-1217e79cda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Phrase_tokens_filtered'] = train_df['Phrase_tokens'].apply(stopwords_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbc28d2b-f8ec-4fd0-9c78-a5370ae25b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_clean</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>Phrase_tokens_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>hearst s</td>\n",
       "      <td>[hearst, s]</td>\n",
       "      <td>[hearst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>[avuncular]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>chortles</td>\n",
       "      <td>[chortles]</td>\n",
       "      <td>[chortles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "                                             Phrase_clean  \\\n",
       "0       a series of escapades demonstrating the adage ...   \n",
       "1       a series of escapades demonstrating the adage ...   \n",
       "2                                                a series   \n",
       "3                                                       a   \n",
       "4                                                  series   \n",
       "...                                                   ...   \n",
       "156055                                           hearst s   \n",
       "156056                          forced avuncular chortles   \n",
       "156057                                 avuncular chortles   \n",
       "156058                                          avuncular   \n",
       "156059                                           chortles   \n",
       "\n",
       "                                            Phrase_tokens  \\\n",
       "0       [a, series, of, escapades, demonstrating, the,...   \n",
       "1       [a, series, of, escapades, demonstrating, the,...   \n",
       "2                                             [a, series]   \n",
       "3                                                     [a]   \n",
       "4                                                [series]   \n",
       "...                                                   ...   \n",
       "156055                                        [hearst, s]   \n",
       "156056                      [forced, avuncular, chortles]   \n",
       "156057                              [avuncular, chortles]   \n",
       "156058                                        [avuncular]   \n",
       "156059                                         [chortles]   \n",
       "\n",
       "                                   Phrase_tokens_filtered  \n",
       "0       [series, escapades, demonstrating, adage, good...  \n",
       "1       [series, escapades, demonstrating, adage, good...  \n",
       "2                                                [series]  \n",
       "3                                                      []  \n",
       "4                                                [series]  \n",
       "...                                                   ...  \n",
       "156055                                           [hearst]  \n",
       "156056                      [forced, avuncular, chortles]  \n",
       "156057                              [avuncular, chortles]  \n",
       "156058                                        [avuncular]  \n",
       "156059                                         [chortles]  \n",
       "\n",
       "[156060 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b30fb2-f43a-4d82-ad1b-8e51c538d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['PhraseId','SentenceId'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01e3d801-b6be-40ad-a6c5-5481d54625c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_clean</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>Phrase_tokens_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>hearst s</td>\n",
       "      <td>[hearst, s]</td>\n",
       "      <td>[hearst]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>[avuncular]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>chortles</td>\n",
       "      <td>[chortles]</td>\n",
       "      <td>[chortles]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "                                             Phrase_clean  \\\n",
       "0       a series of escapades demonstrating the adage ...   \n",
       "1       a series of escapades demonstrating the adage ...   \n",
       "2                                                a series   \n",
       "3                                                       a   \n",
       "4                                                  series   \n",
       "...                                                   ...   \n",
       "156055                                           hearst s   \n",
       "156056                          forced avuncular chortles   \n",
       "156057                                 avuncular chortles   \n",
       "156058                                          avuncular   \n",
       "156059                                           chortles   \n",
       "\n",
       "                                            Phrase_tokens  \\\n",
       "0       [a, series, of, escapades, demonstrating, the,...   \n",
       "1       [a, series, of, escapades, demonstrating, the,...   \n",
       "2                                             [a, series]   \n",
       "3                                                     [a]   \n",
       "4                                                [series]   \n",
       "...                                                   ...   \n",
       "156055                                        [hearst, s]   \n",
       "156056                      [forced, avuncular, chortles]   \n",
       "156057                              [avuncular, chortles]   \n",
       "156058                                        [avuncular]   \n",
       "156059                                         [chortles]   \n",
       "\n",
       "                                   Phrase_tokens_filtered  \n",
       "0       [series, escapades, demonstrating, adage, good...  \n",
       "1       [series, escapades, demonstrating, adage, good...  \n",
       "2                                                [series]  \n",
       "3                                                      []  \n",
       "4                                                [series]  \n",
       "...                                                   ...  \n",
       "156055                                           [hearst]  \n",
       "156056                      [forced, avuncular, chortles]  \n",
       "156057                              [avuncular, chortles]  \n",
       "156058                                        [avuncular]  \n",
       "156059                                         [chortles]  \n",
       "\n",
       "[156060 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82318bd5-6206-40d4-80ad-5e67a621c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_for_tfidf'] = train_df['Phrase_tokens_filtered'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e7bef55-d1f6-4754-8edc-4811e082d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4fbfeb9-0b9a-40d3-b4da-0982cdf36d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=2, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33cd132d-011c-47c5-af28-0945468f35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_df['text_for_tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c25b56d-e479-496a-8e4a-00ab0adccbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c9136ac-98be-43b2-a894-5d08ba279cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),  # 稀疏矩阵转密集矩阵\n",
    "    columns=feature_names,   # 列名为词汇\n",
    "    index=train_df.index     # 行索引和原数据一致\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0959168-4d34-4405-b7e5-55df072448f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 矩阵形状：(156060, 5000)\n",
      "提取的特征词汇数量：5000\n",
      "\n",
      "前10个特征词汇： ['10' '100' '101' '11' '12' '12yearold' '13' '15' '18' '18yearold']\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF 矩阵形状：{tfidf_matrix.shape}\")  # (样本数, 特征数)\n",
    "print(f\"提取的特征词汇数量：{len(feature_names)}\")\n",
    "print(\"\\n前10个特征词汇：\", feature_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8570c576-1738-41c1-845f-f85f158bfef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4ddf8e2-d478-489a-b3c8-ce84b130a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_df['Phrase_tokens_filtered'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd5aef1-eb66-41b8-a5ca-e0acbcc4f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [tokens for tokens in corpus if len(tokens) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8292168-2bef-471f-bb71-10c9d71f97de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['series',\n",
       "  'escapades',\n",
       "  'demonstrating',\n",
       "  'adage',\n",
       "  'good',\n",
       "  'goose',\n",
       "  'also',\n",
       "  'good',\n",
       "  'gander',\n",
       "  'occasionally',\n",
       "  'amuses',\n",
       "  'none',\n",
       "  'amounts',\n",
       "  'much',\n",
       "  'story'],\n",
       " ['series', 'escapades', 'demonstrating', 'adage', 'good', 'goose'],\n",
       " ['series'],\n",
       " ['series'],\n",
       " ['escapades', 'demonstrating', 'adage', 'good', 'goose'],\n",
       " ['escapades', 'demonstrating', 'adage', 'good', 'goose'],\n",
       " ['escapades'],\n",
       " ['demonstrating', 'adage', 'good', 'goose'],\n",
       " ['demonstrating', 'adage'],\n",
       " ['demonstrating'],\n",
       " ['adage'],\n",
       " ['adage'],\n",
       " ['good', 'goose'],\n",
       " ['good', 'goose'],\n",
       " ['good', 'goose'],\n",
       " ['good', 'goose'],\n",
       " ['good'],\n",
       " ['goose'],\n",
       " ['goose'],\n",
       " ['goose'],\n",
       " ['also',\n",
       "  'good',\n",
       "  'gander',\n",
       "  'occasionally',\n",
       "  'amuses',\n",
       "  'none',\n",
       "  'amounts',\n",
       "  'much',\n",
       "  'story'],\n",
       " ['also',\n",
       "  'good',\n",
       "  'gander',\n",
       "  'occasionally',\n",
       "  'amuses',\n",
       "  'none',\n",
       "  'amounts',\n",
       "  'much',\n",
       "  'story'],\n",
       " ['also'],\n",
       " ['also'],\n",
       " ['good',\n",
       "  'gander',\n",
       "  'occasionally',\n",
       "  'amuses',\n",
       "  'none',\n",
       "  'amounts',\n",
       "  'much',\n",
       "  'story'],\n",
       " ['gander', 'occasionally', 'amuses', 'none', 'amounts', 'much', 'story'],\n",
       " ['gander', 'occasionally', 'amuses', 'none', 'amounts', 'much', 'story'],\n",
       " ['gander'],\n",
       " ['gander'],\n",
       " ['gander'],\n",
       " ['occasionally', 'amuses', 'none', 'amounts', 'much', 'story'],\n",
       " ['occasionally', 'amuses', 'none', 'amounts', 'much', 'story'],\n",
       " ['occasionally'],\n",
       " ['amuses', 'none', 'amounts', 'much', 'story'],\n",
       " ['amuses'],\n",
       " ['none', 'amounts', 'much', 'story'],\n",
       " ['none', 'amounts', 'much', 'story'],\n",
       " ['none'],\n",
       " ['amounts', 'much', 'story'],\n",
       " ['amounts', 'much', 'story'],\n",
       " ['amounts', 'much', 'story'],\n",
       " ['amounts'],\n",
       " ['much', 'story'],\n",
       " ['much', 'story'],\n",
       " ['much'],\n",
       " ['story'],\n",
       " ['story'],\n",
       " ['story'],\n",
       " ['quiet', 'introspective', 'entertaining', 'independent', 'worth', 'seeking'],\n",
       " ['quiet', 'introspective', 'entertaining', 'independent'],\n",
       " ['quiet', 'introspective', 'entertaining', 'independent'],\n",
       " ['quiet', 'introspective', 'entertaining'],\n",
       " ['quiet'],\n",
       " ['introspective', 'entertaining'],\n",
       " ['introspective', 'entertaining'],\n",
       " ['introspective'],\n",
       " ['introspective'],\n",
       " ['entertaining'],\n",
       " ['independent'],\n",
       " ['worth', 'seeking'],\n",
       " ['worth', 'seeking'],\n",
       " ['worth'],\n",
       " ['worth'],\n",
       " ['seeking'],\n",
       " ['even',\n",
       "  'fans',\n",
       "  'ismail',\n",
       "  'merchant',\n",
       "  'work',\n",
       "  'suspect',\n",
       "  'would',\n",
       "  'hard',\n",
       "  'time',\n",
       "  'sitting',\n",
       "  'one'],\n",
       " ['even', 'fans', 'ismail', 'merchant', 'work'],\n",
       " ['even', 'fans'],\n",
       " ['even'],\n",
       " ['fans'],\n",
       " ['ismail', 'merchant', 'work'],\n",
       " ['ismail', 'merchant', 'work'],\n",
       " ['ismail', 'merchant'],\n",
       " ['ismail'],\n",
       " ['merchant'],\n",
       " ['merchant'],\n",
       " ['work'],\n",
       " ['suspect', 'would', 'hard', 'time', 'sitting', 'one'],\n",
       " ['suspect'],\n",
       " ['suspect'],\n",
       " ['suspect'],\n",
       " ['suspect'],\n",
       " ['would', 'hard', 'time', 'sitting', 'one'],\n",
       " ['would', 'hard', 'time', 'sitting', 'one'],\n",
       " ['would'],\n",
       " ['hard', 'time', 'sitting', 'one'],\n",
       " ['hard', 'time', 'sitting', 'one'],\n",
       " ['hard', 'time'],\n",
       " ['hard', 'time'],\n",
       " ['hard'],\n",
       " ['time'],\n",
       " ['sitting', 'one'],\n",
       " ['sitting'],\n",
       " ['one'],\n",
       " ['one'],\n",
       " ['one'],\n",
       " ['positively',\n",
       "  'thrilling',\n",
       "  'combination',\n",
       "  'ethnography',\n",
       "  'intrigue',\n",
       "  'betrayal',\n",
       "  'deceit',\n",
       "  'murder',\n",
       "  'shakespearean',\n",
       "  'tragedy',\n",
       "  'juicy',\n",
       "  'soap',\n",
       "  'opera'],\n",
       " ['positively',\n",
       "  'thrilling',\n",
       "  'combination',\n",
       "  'ethnography',\n",
       "  'intrigue',\n",
       "  'betrayal',\n",
       "  'deceit',\n",
       "  'murder',\n",
       "  'shakespearean',\n",
       "  'tragedy',\n",
       "  'juicy',\n",
       "  'soap',\n",
       "  'opera'],\n",
       " ['positively',\n",
       "  'thrilling',\n",
       "  'combination',\n",
       "  'ethnography',\n",
       "  'intrigue',\n",
       "  'betrayal',\n",
       "  'deceit',\n",
       "  'murder'],\n",
       " ['positively', 'thrilling', 'combination'],\n",
       " ['positively', 'thrilling', 'combination'],\n",
       " ['positively'],\n",
       " ['thrilling', 'combination'],\n",
       " ['thrilling'],\n",
       " ['combination'],\n",
       " ['ethnography', 'intrigue', 'betrayal', 'deceit', 'murder'],\n",
       " ['ethnography', 'intrigue', 'betrayal', 'deceit', 'murder'],\n",
       " ['ethnography'],\n",
       " ['ethnography'],\n",
       " ['intrigue', 'betrayal', 'deceit', 'murder'],\n",
       " ['intrigue', 'betrayal', 'deceit', 'murder'],\n",
       " ['intrigue', 'betrayal', 'deceit', 'murder'],\n",
       " ['intrigue'],\n",
       " ['betrayal', 'deceit', 'murder'],\n",
       " ['betrayal', 'deceit', 'murder'],\n",
       " ['betrayal'],\n",
       " ['deceit', 'murder'],\n",
       " ['deceit', 'murder'],\n",
       " ['deceit'],\n",
       " ['deceit'],\n",
       " ['murder'],\n",
       " ['shakespearean', 'tragedy', 'juicy', 'soap', 'opera'],\n",
       " ['shakespearean', 'tragedy', 'juicy', 'soap', 'opera'],\n",
       " ['shakespearean', 'tragedy'],\n",
       " ['shakespearean', 'tragedy'],\n",
       " ['shakespearean', 'tragedy'],\n",
       " ['shakespearean'],\n",
       " ['tragedy'],\n",
       " ['juicy', 'soap', 'opera'],\n",
       " ['juicy', 'soap', 'opera'],\n",
       " ['juicy'],\n",
       " ['soap', 'opera'],\n",
       " ['soap'],\n",
       " ['opera'],\n",
       " ['aggressive', 'selfglorification', 'manipulative', 'whitewash'],\n",
       " ['aggressive', 'selfglorification', 'manipulative', 'whitewash'],\n",
       " ['aggressive'],\n",
       " ['selfglorification', 'manipulative', 'whitewash'],\n",
       " ['selfglorification'],\n",
       " ['selfglorification'],\n",
       " ['manipulative', 'whitewash'],\n",
       " ['manipulative', 'whitewash'],\n",
       " ['manipulative'],\n",
       " ['whitewash'],\n",
       " ['comedydrama',\n",
       "  'nearly',\n",
       "  'epic',\n",
       "  'proportions',\n",
       "  'rooted',\n",
       "  'sincere',\n",
       "  'performance',\n",
       "  'title',\n",
       "  'character',\n",
       "  'undergoing',\n",
       "  'midlife',\n",
       "  'crisis'],\n",
       " ['comedydrama', 'nearly', 'epic', 'proportions'],\n",
       " ['comedydrama'],\n",
       " ['comedydrama'],\n",
       " ['nearly', 'epic', 'proportions'],\n",
       " ['nearly', 'epic', 'proportions'],\n",
       " ['nearly', 'epic'],\n",
       " ['nearly'],\n",
       " ['epic'],\n",
       " ['proportions'],\n",
       " ['rooted',\n",
       "  'sincere',\n",
       "  'performance',\n",
       "  'title',\n",
       "  'character',\n",
       "  'undergoing',\n",
       "  'midlife',\n",
       "  'crisis'],\n",
       " ['rooted',\n",
       "  'sincere',\n",
       "  'performance',\n",
       "  'title',\n",
       "  'character',\n",
       "  'undergoing',\n",
       "  'midlife',\n",
       "  'crisis'],\n",
       " ['rooted', 'sincere', 'performance'],\n",
       " ['rooted'],\n",
       " ['sincere', 'performance'],\n",
       " ['sincere', 'performance'],\n",
       " ['sincere', 'performance'],\n",
       " ['sincere'],\n",
       " ['performance'],\n",
       " ['title', 'character', 'undergoing', 'midlife', 'crisis'],\n",
       " ['title', 'character', 'undergoing', 'midlife', 'crisis'],\n",
       " ['title', 'character'],\n",
       " ['title', 'character'],\n",
       " ['title'],\n",
       " ['character'],\n",
       " ['undergoing', 'midlife', 'crisis'],\n",
       " ['undergoing'],\n",
       " ['midlife', 'crisis'],\n",
       " ['midlife'],\n",
       " ['crisis'],\n",
       " ['narratively', 'trouble', 'every', 'day', 'plodding', 'mess'],\n",
       " ['narratively'],\n",
       " ['trouble', 'every', 'day', 'plodding', 'mess'],\n",
       " ['trouble', 'every', 'day', 'plodding', 'mess'],\n",
       " ['trouble', 'every', 'day'],\n",
       " ['trouble'],\n",
       " ['every', 'day'],\n",
       " ['every'],\n",
       " ['day'],\n",
       " ['plodding', 'mess'],\n",
       " ['plodding', 'mess'],\n",
       " ['plodding', 'mess'],\n",
       " ['plodding', 'mess'],\n",
       " ['plodding'],\n",
       " ['mess'],\n",
       " ['importance',\n",
       "  'earnest',\n",
       "  'thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['importance'],\n",
       " ['importance'],\n",
       " ['earnest',\n",
       "  'thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['earnest',\n",
       "  'thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['earnest',\n",
       "  'thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['earnest'],\n",
       " ['earnest'],\n",
       " ['thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['thick',\n",
       "  'wit',\n",
       "  'plays',\n",
       "  'like',\n",
       "  'reading',\n",
       "  'bartlett',\n",
       "  'familiar',\n",
       "  'quotations'],\n",
       " ['thick'],\n",
       " ['wit', 'plays', 'like', 'reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['wit', 'plays', 'like', 'reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['wit'],\n",
       " ['plays', 'like', 'reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['plays', 'like', 'reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['plays'],\n",
       " ['like', 'reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['like'],\n",
       " ['reading', 'bartlett', 'familiar', 'quotations'],\n",
       " ['reading'],\n",
       " ['reading'],\n",
       " ['bartlett', 'familiar', 'quotations'],\n",
       " ['bartlett', 'familiar', 'quotations'],\n",
       " ['bartlett'],\n",
       " ['bartlett'],\n",
       " ['familiar', 'quotations'],\n",
       " ['familiar'],\n",
       " ['quotations'],\n",
       " ['nt', 'leave', 'much'],\n",
       " ['nt', 'leave', 'much'],\n",
       " ['nt', 'leave', 'much'],\n",
       " ['nt', 'leave', 'much'],\n",
       " ['nt'],\n",
       " ['nt'],\n",
       " ['leave', 'much'],\n",
       " ['leave'],\n",
       " ['leave'],\n",
       " ['much'],\n",
       " ['could', 'hate', 'reason'],\n",
       " ['could', 'hate', 'reason'],\n",
       " ['could', 'hate', 'reason'],\n",
       " ['could'],\n",
       " ['hate', 'reason'],\n",
       " ['hate'],\n",
       " ['hate'],\n",
       " ['reason'],\n",
       " ['reason'],\n",
       " ['reason'],\n",
       " ['reason'],\n",
       " ['little',\n",
       "  'recommend',\n",
       "  'snow',\n",
       "  'dogs',\n",
       "  'unless',\n",
       "  'one',\n",
       "  'considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['little',\n",
       "  'recommend',\n",
       "  'snow',\n",
       "  'dogs',\n",
       "  'unless',\n",
       "  'one',\n",
       "  'considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['little',\n",
       "  'recommend',\n",
       "  'snow',\n",
       "  'dogs',\n",
       "  'unless',\n",
       "  'one',\n",
       "  'considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['little', 'recommend', 'snow', 'dogs'],\n",
       " ['little', 'recommend', 'snow', 'dogs'],\n",
       " ['little', 'recommend', 'snow', 'dogs'],\n",
       " ['little'],\n",
       " ['recommend', 'snow', 'dogs'],\n",
       " ['recommend', 'snow', 'dogs'],\n",
       " ['recommend'],\n",
       " ['snow', 'dogs'],\n",
       " ['snow'],\n",
       " ['dogs'],\n",
       " ['unless',\n",
       "  'one',\n",
       "  'considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['unless'],\n",
       " ['one',\n",
       "  'considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['considers',\n",
       "  'cliched',\n",
       "  'dialogue',\n",
       "  'perverse',\n",
       "  'escapism',\n",
       "  'source',\n",
       "  'high',\n",
       "  'hilarity'],\n",
       " ['considers'],\n",
       " ['cliched', 'dialogue', 'perverse', 'escapism', 'source', 'high', 'hilarity'],\n",
       " ['cliched', 'dialogue', 'perverse', 'escapism'],\n",
       " ['cliched', 'dialogue'],\n",
       " ['cliched', 'dialogue'],\n",
       " ['cliched'],\n",
       " ['dialogue'],\n",
       " ['perverse', 'escapism'],\n",
       " ['perverse'],\n",
       " ['escapism'],\n",
       " ['source', 'high', 'hilarity'],\n",
       " ['source'],\n",
       " ['source'],\n",
       " ['high', 'hilarity'],\n",
       " ['high', 'hilarity'],\n",
       " ['high'],\n",
       " ['hilarity'],\n",
       " ['kung',\n",
       "  'pow',\n",
       "  'oedekerk',\n",
       "  'realization',\n",
       "  'childhood',\n",
       "  'dream',\n",
       "  'martialarts',\n",
       "  'flick',\n",
       "  'proves',\n",
       "  'sometimes',\n",
       "  'dreams',\n",
       "  'youth',\n",
       "  'remain'],\n",
       " ['kung', 'pow'],\n",
       " ['kung'],\n",
       " ['pow'],\n",
       " ['oedekerk',\n",
       "  'realization',\n",
       "  'childhood',\n",
       "  'dream',\n",
       "  'martialarts',\n",
       "  'flick',\n",
       "  'proves',\n",
       "  'sometimes',\n",
       "  'dreams',\n",
       "  'youth',\n",
       "  'remain'],\n",
       " ['oedekerk',\n",
       "  'realization',\n",
       "  'childhood',\n",
       "  'dream',\n",
       "  'martialarts',\n",
       "  'flick',\n",
       "  'proves',\n",
       "  'sometimes',\n",
       "  'dreams',\n",
       "  'youth',\n",
       "  'remain'],\n",
       " ['oedekerk', 'realization', 'childhood', 'dream', 'martialarts', 'flick'],\n",
       " ['oedekerk', 'realization', 'childhood', 'dream', 'martialarts', 'flick'],\n",
       " ['oedekerk', 'realization', 'childhood', 'dream', 'martialarts', 'flick'],\n",
       " ['oedekerk', 'realization', 'childhood', 'dream', 'martialarts', 'flick'],\n",
       " ['oedekerk', 'realization', 'childhood', 'dream'],\n",
       " ['oedekerk', 'realization'],\n",
       " ['oedekerk'],\n",
       " ['oedekerk'],\n",
       " ['realization'],\n",
       " ['childhood', 'dream'],\n",
       " ['childhood', 'dream'],\n",
       " ['childhood', 'dream'],\n",
       " ['childhood'],\n",
       " ['dream'],\n",
       " ['martialarts', 'flick'],\n",
       " ['martialarts', 'flick'],\n",
       " ['martialarts', 'flick'],\n",
       " ['martialarts', 'flick'],\n",
       " ['martialarts', 'flick'],\n",
       " ['martialarts'],\n",
       " ['flick'],\n",
       " ['proves', 'sometimes', 'dreams', 'youth', 'remain'],\n",
       " ['proves'],\n",
       " ['sometimes', 'dreams', 'youth', 'remain'],\n",
       " ['sometimes', 'dreams', 'youth', 'remain'],\n",
       " ['sometimes'],\n",
       " ['dreams', 'youth', 'remain'],\n",
       " ['dreams', 'youth'],\n",
       " ['dreams'],\n",
       " ['dreams'],\n",
       " ['youth'],\n",
       " ['youth'],\n",
       " ['remain'],\n",
       " ['remain'],\n",
       " ['remain'],\n",
       " ['performances', 'absolute', 'joy'],\n",
       " ['performances'],\n",
       " ['performances'],\n",
       " ['absolute', 'joy'],\n",
       " ['absolute', 'joy'],\n",
       " ['absolute', 'joy'],\n",
       " ['absolute', 'joy'],\n",
       " ['absolute'],\n",
       " ['joy'],\n",
       " ['fresnadillo',\n",
       "  'something',\n",
       "  'serious',\n",
       "  'say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['fresnadillo'],\n",
       " ['something',\n",
       "  'serious',\n",
       "  'say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['something',\n",
       "  'serious',\n",
       "  'say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['something',\n",
       "  'serious',\n",
       "  'say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['something'],\n",
       " ['serious',\n",
       "  'say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['serious'],\n",
       " ['say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['say',\n",
       "  'ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['say'],\n",
       " ['ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['ways',\n",
       "  'extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['ways'],\n",
       " ['ways'],\n",
       " ['extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['extravagant',\n",
       "  'chance',\n",
       "  'distort',\n",
       "  'perspective',\n",
       "  'throw',\n",
       "  'us',\n",
       "  'path',\n",
       "  'good',\n",
       "  'sense'],\n",
       " ['extravagant', 'chance'],\n",
       " ['extravagant'],\n",
       " ['chance'],\n",
       " ['distort', 'perspective', 'throw', 'us', 'path', 'good', 'sense'],\n",
       " ['distort', 'perspective', 'throw', 'us', 'path', 'good', 'sense'],\n",
       " ['distort', 'perspective'],\n",
       " ['distort', 'perspective'],\n",
       " ['distort'],\n",
       " ['perspective'],\n",
       " ['perspective'],\n",
       " ['throw', 'us', 'path', 'good', 'sense'],\n",
       " ['throw', 'us'],\n",
       " ['throw'],\n",
       " ['us'],\n",
       " ['path', 'good', 'sense'],\n",
       " ['path', 'good', 'sense'],\n",
       " ['path'],\n",
       " ['path'],\n",
       " ['good', 'sense'],\n",
       " ['good', 'sense'],\n",
       " ['sense'],\n",
       " ['still', 'like', 'moonlight', 'mile', 'better', 'judgment', 'damned'],\n",
       " ['still', 'like', 'moonlight', 'mile', 'better', 'judgment', 'damned'],\n",
       " ['still'],\n",
       " ['like', 'moonlight', 'mile', 'better', 'judgment', 'damned'],\n",
       " ['like', 'moonlight', 'mile', 'better', 'judgment', 'damned'],\n",
       " ['moonlight', 'mile', 'better', 'judgment', 'damned'],\n",
       " ['moonlight', 'mile', 'better', 'judgment'],\n",
       " ['moonlight'],\n",
       " ['mile', 'better', 'judgment'],\n",
       " ['mile'],\n",
       " ['better', 'judgment'],\n",
       " ['better', 'judgment'],\n",
       " ['better'],\n",
       " ['judgment'],\n",
       " ['damned'],\n",
       " ['damned'],\n",
       " ['welcome',\n",
       "  'relief',\n",
       "  'baseball',\n",
       "  'movies',\n",
       "  'try',\n",
       "  'hard',\n",
       "  'mythic',\n",
       "  'one',\n",
       "  'sweet',\n",
       "  'modest',\n",
       "  'ultimately',\n",
       "  'winning',\n",
       "  'story'],\n",
       " ['welcome', 'relief', 'baseball', 'movies', 'try', 'hard', 'mythic'],\n",
       " ['welcome', 'relief'],\n",
       " ['welcome', 'relief'],\n",
       " ['welcome'],\n",
       " ['relief'],\n",
       " ['baseball', 'movies', 'try', 'hard', 'mythic'],\n",
       " ['baseball', 'movies', 'try', 'hard', 'mythic'],\n",
       " ['baseball', 'movies'],\n",
       " ['baseball'],\n",
       " ['movies'],\n",
       " ['try', 'hard', 'mythic'],\n",
       " ['try', 'hard', 'mythic'],\n",
       " ['try'],\n",
       " ['hard', 'mythic'],\n",
       " ['hard', 'mythic'],\n",
       " ['mythic'],\n",
       " ['mythic'],\n",
       " ['mythic'],\n",
       " ['one', 'sweet', 'modest', 'ultimately', 'winning', 'story'],\n",
       " ['one', 'sweet', 'modest', 'ultimately', 'winning', 'story'],\n",
       " ['sweet', 'modest', 'ultimately', 'winning', 'story'],\n",
       " ['sweet', 'modest', 'ultimately', 'winning', 'story'],\n",
       " ['sweet', 'modest', 'ultimately', 'winning', 'story'],\n",
       " ['sweet', 'modest'],\n",
       " ['sweet', 'modest'],\n",
       " ['sweet', 'modest'],\n",
       " ['sweet'],\n",
       " ['sweet'],\n",
       " ['modest'],\n",
       " ['ultimately', 'winning', 'story'],\n",
       " ['ultimately'],\n",
       " ['winning', 'story'],\n",
       " ['winning'],\n",
       " ['bilingual', 'charmer', 'like', 'woman', 'inspired'],\n",
       " ['bilingual', 'charmer'],\n",
       " ['bilingual', 'charmer'],\n",
       " ['bilingual', 'charmer'],\n",
       " ['bilingual'],\n",
       " ['charmer'],\n",
       " ['like', 'woman', 'inspired'],\n",
       " ['like', 'woman', 'inspired'],\n",
       " ['woman', 'inspired'],\n",
       " ['woman'],\n",
       " ['woman'],\n",
       " ['inspired'],\n",
       " ['inspired'],\n",
       " ['inspired'],\n",
       " ['like',\n",
       "  'less',\n",
       "  'dizzily',\n",
       "  'gorgeous',\n",
       "  'companion',\n",
       "  'mr',\n",
       "  'wong',\n",
       "  'mood',\n",
       "  'love',\n",
       "  'much',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'movie',\n",
       "  'despite',\n",
       "  'mainland',\n",
       "  'setting'],\n",
       " ['like', 'less', 'dizzily', 'gorgeous', 'companion', 'mr'],\n",
       " ['less', 'dizzily', 'gorgeous', 'companion', 'mr'],\n",
       " ['less', 'dizzily', 'gorgeous', 'companion'],\n",
       " ['less', 'dizzily', 'gorgeous', 'companion'],\n",
       " ['less', 'dizzily', 'gorgeous'],\n",
       " ['less'],\n",
       " ['dizzily', 'gorgeous'],\n",
       " ['dizzily'],\n",
       " ['gorgeous'],\n",
       " ['companion'],\n",
       " ['mr'],\n",
       " ['mr'],\n",
       " ['wong',\n",
       "  'mood',\n",
       "  'love',\n",
       "  'much',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'movie',\n",
       "  'despite',\n",
       "  'mainland',\n",
       "  'setting'],\n",
       " ['wong'],\n",
       " ['mood',\n",
       "  'love',\n",
       "  'much',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'movie',\n",
       "  'despite',\n",
       "  'mainland',\n",
       "  'setting'],\n",
       " ['mood',\n",
       "  'love',\n",
       "  'much',\n",
       "  'hong',\n",
       "  'kong',\n",
       "  'movie',\n",
       "  'despite',\n",
       "  'mainland',\n",
       "  'setting'],\n",
       " ['mood', 'love', 'much', 'hong', 'kong', 'movie'],\n",
       " ['mood', 'love', 'much', 'hong', 'kong', 'movie'],\n",
       " ['mood', 'love', 'much', 'hong', 'kong', 'movie'],\n",
       " ['mood'],\n",
       " ['mood'],\n",
       " ['love', 'much', 'hong', 'kong', 'movie'],\n",
       " ['love', 'much', 'hong', 'kong', 'movie'],\n",
       " ['love', 'much'],\n",
       " ['love'],\n",
       " ['love'],\n",
       " ['much'],\n",
       " ['hong', 'kong', 'movie'],\n",
       " ['hong', 'kong', 'movie'],\n",
       " ['hong'],\n",
       " ['kong', 'movie'],\n",
       " ['kong'],\n",
       " ['movie'],\n",
       " ['despite', 'mainland', 'setting'],\n",
       " ['despite'],\n",
       " ['mainland', 'setting'],\n",
       " ['mainland', 'setting'],\n",
       " ['mainland'],\n",
       " ['setting'],\n",
       " ['inept', 'bigscreen', 'remakes', 'avengers', 'wild', 'wild', 'west'],\n",
       " ['inept', 'bigscreen', 'remakes', 'avengers', 'wild', 'wild', 'west'],\n",
       " ['inept'],\n",
       " ['inept'],\n",
       " ['bigscreen', 'remakes', 'avengers', 'wild', 'wild', 'west'],\n",
       " ['bigscreen', 'remakes', 'avengers', 'wild', 'wild', 'west'],\n",
       " ['bigscreen', 'remakes'],\n",
       " ['bigscreen'],\n",
       " ['remakes'],\n",
       " ['avengers', 'wild', 'wild', 'west'],\n",
       " ['avengers', 'wild', 'wild', 'west'],\n",
       " ['avengers'],\n",
       " ['avengers'],\n",
       " ['avengers'],\n",
       " ['wild', 'wild', 'west'],\n",
       " ['wild', 'wild', 'west'],\n",
       " ['wild'],\n",
       " ['wild', 'west'],\n",
       " ['west'],\n",
       " ['everything', 'expect', 'nothing'],\n",
       " ['everything', 'expect', 'nothing'],\n",
       " ['everything', 'expect', 'nothing'],\n",
       " ['everything', 'expect', 'nothing'],\n",
       " ['everything'],\n",
       " ['expect', 'nothing'],\n",
       " ['expect', 'nothing'],\n",
       " ['expect', 'nothing'],\n",
       " ['expect', 'nothing'],\n",
       " ['expect'],\n",
       " ['expect'],\n",
       " ['nothing'],\n",
       " ['nothing'],\n",
       " ['best', 'indie', 'year', 'far'],\n",
       " ['best'],\n",
       " ['indie', 'year', 'far'],\n",
       " ['indie', 'year', 'far'],\n",
       " ['indie', 'year'],\n",
       " ['indie', 'year'],\n",
       " ['indie'],\n",
       " ['year'],\n",
       " ['year'],\n",
       " ['year'],\n",
       " ['far'],\n",
       " ['far'],\n",
       " ['hatfield',\n",
       "  'hicks',\n",
       "  'make',\n",
       "  'oddest',\n",
       "  'couples',\n",
       "  'sense',\n",
       "  'movie',\n",
       "  'becomes',\n",
       "  'study',\n",
       "  'gambles',\n",
       "  'publishing',\n",
       "  'world',\n",
       "  'offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['hatfield',\n",
       "  'hicks',\n",
       "  'make',\n",
       "  'oddest',\n",
       "  'couples',\n",
       "  'sense',\n",
       "  'movie',\n",
       "  'becomes',\n",
       "  'study',\n",
       "  'gambles',\n",
       "  'publishing',\n",
       "  'world',\n",
       "  'offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['hatfield', 'hicks', 'make', 'oddest', 'couples'],\n",
       " ['hatfield', 'hicks', 'make', 'oddest', 'couples'],\n",
       " ['hatfield', 'hicks', 'make', 'oddest', 'couples'],\n",
       " ['hatfield', 'hicks'],\n",
       " ['hatfield'],\n",
       " ['hatfield'],\n",
       " ['hicks'],\n",
       " ['make', 'oddest', 'couples'],\n",
       " ['make'],\n",
       " ['oddest', 'couples'],\n",
       " ['oddest'],\n",
       " ['oddest'],\n",
       " ['couples'],\n",
       " ['couples'],\n",
       " ['sense',\n",
       "  'movie',\n",
       "  'becomes',\n",
       "  'study',\n",
       "  'gambles',\n",
       "  'publishing',\n",
       "  'world',\n",
       "  'offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['sense'],\n",
       " ['sense'],\n",
       " ['movie',\n",
       "  'becomes',\n",
       "  'study',\n",
       "  'gambles',\n",
       "  'publishing',\n",
       "  'world',\n",
       "  'offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['movie'],\n",
       " ['becomes',\n",
       "  'study',\n",
       "  'gambles',\n",
       "  'publishing',\n",
       "  'world',\n",
       "  'offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['becomes', 'study', 'gambles', 'publishing', 'world'],\n",
       " ['becomes', 'study', 'gambles', 'publishing', 'world'],\n",
       " ['becomes'],\n",
       " ['study', 'gambles', 'publishing', 'world'],\n",
       " ['study'],\n",
       " ['study'],\n",
       " ['gambles', 'publishing', 'world'],\n",
       " ['gambles', 'publishing', 'world'],\n",
       " ['gambles'],\n",
       " ['gambles'],\n",
       " ['publishing', 'world'],\n",
       " ['publishing', 'world'],\n",
       " ['publishing', 'world'],\n",
       " ['publishing'],\n",
       " ['world'],\n",
       " ['offering',\n",
       "  'case',\n",
       "  'study',\n",
       "  'exists',\n",
       "  'apart',\n",
       "  'movie',\n",
       "  'political',\n",
       "  'ramifications'],\n",
       " ['offering'],\n",
       " ['case', 'study', 'exists', 'apart', 'movie', 'political', 'ramifications'],\n",
       " ['case', 'study'],\n",
       " ['case', 'study'],\n",
       " ['case'],\n",
       " ['exists', 'apart', 'movie', 'political', 'ramifications'],\n",
       " ['exists', 'apart', 'movie', 'political', 'ramifications'],\n",
       " ['exists', 'apart'],\n",
       " ['exists'],\n",
       " ['apart'],\n",
       " ['movie', 'political', 'ramifications'],\n",
       " ['movie', 'political', 'ramifications'],\n",
       " ['movie', 'political', 'ramifications'],\n",
       " ['movie'],\n",
       " ['movie'],\n",
       " ['political', 'ramifications'],\n",
       " ['political'],\n",
       " ['ramifications'],\n",
       " ['like',\n",
       "  'going',\n",
       "  'house',\n",
       "  'party',\n",
       "  'watching',\n",
       "  'host',\n",
       "  'defend',\n",
       "  'frothing',\n",
       "  'exgirlfriend'],\n",
       " ['like',\n",
       "  'going',\n",
       "  'house',\n",
       "  'party',\n",
       "  'watching',\n",
       "  'host',\n",
       "  'defend',\n",
       "  'frothing',\n",
       "  'exgirlfriend'],\n",
       " ['like',\n",
       "  'going',\n",
       "  'house',\n",
       "  'party',\n",
       "  'watching',\n",
       "  'host',\n",
       "  'defend',\n",
       "  'frothing',\n",
       "  'exgirlfriend'],\n",
       " ['like',\n",
       "  'going',\n",
       "  'house',\n",
       "  'party',\n",
       "  'watching',\n",
       "  'host',\n",
       "  'defend',\n",
       "  'frothing',\n",
       "  'exgirlfriend'],\n",
       " ['going',\n",
       "  'house',\n",
       "  'party',\n",
       "  'watching',\n",
       "  'host',\n",
       "  'defend',\n",
       "  'frothing',\n",
       "  'exgirlfriend'],\n",
       " ['going', 'house', 'party'],\n",
       " ['going', 'house', 'party'],\n",
       " ['going'],\n",
       " ['house', 'party'],\n",
       " ['house', 'party'],\n",
       " ['house', 'party'],\n",
       " ['house'],\n",
       " ['party'],\n",
       " ['watching', 'host', 'defend', 'frothing', 'exgirlfriend'],\n",
       " ['watching'],\n",
       " ['host', 'defend', 'frothing', 'exgirlfriend'],\n",
       " ['host'],\n",
       " ['host'],\n",
       " ['defend', 'frothing', 'exgirlfriend'],\n",
       " ['defend'],\n",
       " ['defend'],\n",
       " ['frothing', 'exgirlfriend'],\n",
       " ['frothing', 'exgirlfriend'],\n",
       " ['frothing', 'exgirlfriend'],\n",
       " ['frothing'],\n",
       " ['exgirlfriend'],\n",
       " ['chuck',\n",
       "  'norris',\n",
       "  'grenade',\n",
       "  'gag',\n",
       "  'occurs',\n",
       "  '7',\n",
       "  'times',\n",
       "  'windtalkers',\n",
       "  'good',\n",
       "  'indication',\n",
       "  'seriousminded',\n",
       "  'film'],\n",
       " ['chuck', 'norris', 'grenade', 'gag'],\n",
       " ['chuck', 'norris', 'grenade', 'gag'],\n",
       " ['chuck', 'norris', 'grenade', 'gag'],\n",
       " ['chuck'],\n",
       " ['norris', 'grenade', 'gag'],\n",
       " ['norris'],\n",
       " ['grenade', 'gag'],\n",
       " ['grenade', 'gag'],\n",
       " ['grenade'],\n",
       " ['gag'],\n",
       " ['gag'],\n",
       " ['occurs',\n",
       "  '7',\n",
       "  'times',\n",
       "  'windtalkers',\n",
       "  'good',\n",
       "  'indication',\n",
       "  'seriousminded',\n",
       "  'film'],\n",
       " ['occurs',\n",
       "  '7',\n",
       "  'times',\n",
       "  'windtalkers',\n",
       "  'good',\n",
       "  'indication',\n",
       "  'seriousminded',\n",
       "  'film'],\n",
       " ['occurs'],\n",
       " ['7', 'times', 'windtalkers', 'good', 'indication', 'seriousminded', 'film'],\n",
       " ['7', 'times', 'windtalkers'],\n",
       " ['7', 'times'],\n",
       " ['7', 'times'],\n",
       " ['7'],\n",
       " ['times'],\n",
       " ['windtalkers'],\n",
       " ['windtalkers'],\n",
       " ['good', 'indication', 'seriousminded', 'film'],\n",
       " ['good', 'indication', 'seriousminded', 'film'],\n",
       " ['good', 'indication'],\n",
       " ['good', 'indication'],\n",
       " ['indication'],\n",
       " ['seriousminded', 'film'],\n",
       " ['seriousminded', 'film'],\n",
       " ['seriousminded', 'film'],\n",
       " ['seriousminded', 'film'],\n",
       " ['seriousminded'],\n",
       " ['film'],\n",
       " ['film'],\n",
       " ['plot', 'romantic', 'comedy', 'boilerplate', 'start', 'finish'],\n",
       " ['plot'],\n",
       " ['plot'],\n",
       " ['romantic', 'comedy', 'boilerplate', 'start', 'finish'],\n",
       " ['romantic', 'comedy', 'boilerplate', 'start', 'finish'],\n",
       " ['romantic', 'comedy', 'boilerplate', 'start', 'finish'],\n",
       " ['romantic', 'comedy', 'boilerplate', 'start'],\n",
       " ['romantic', 'comedy', 'boilerplate'],\n",
       " ['romantic'],\n",
       " ['comedy', 'boilerplate'],\n",
       " ['comedy'],\n",
       " ['boilerplate'],\n",
       " ['start'],\n",
       " ['start'],\n",
       " ['finish'],\n",
       " ['finish'],\n",
       " ['arrives',\n",
       "  'impeccable',\n",
       "  'pedigree',\n",
       "  'mongrel',\n",
       "  'pep',\n",
       "  'almost',\n",
       "  'indecipherable',\n",
       "  'plot',\n",
       "  'complications'],\n",
       " ['arrives',\n",
       "  'impeccable',\n",
       "  'pedigree',\n",
       "  'mongrel',\n",
       "  'pep',\n",
       "  'almost',\n",
       "  'indecipherable',\n",
       "  'plot',\n",
       "  'complications'],\n",
       " ['arrives',\n",
       "  'impeccable',\n",
       "  'pedigree',\n",
       "  'mongrel',\n",
       "  'pep',\n",
       "  'almost',\n",
       "  'indecipherable',\n",
       "  'plot',\n",
       "  'complications'],\n",
       " ['arrives'],\n",
       " ['impeccable',\n",
       "  'pedigree',\n",
       "  'mongrel',\n",
       "  'pep',\n",
       "  'almost',\n",
       "  'indecipherable',\n",
       "  'plot',\n",
       "  'complications'],\n",
       " ['impeccable',\n",
       "  'pedigree',\n",
       "  'mongrel',\n",
       "  'pep',\n",
       "  'almost',\n",
       "  'indecipherable',\n",
       "  'plot',\n",
       "  'complications'],\n",
       " ['impeccable', 'pedigree', 'mongrel', 'pep', 'almost'],\n",
       " ['impeccable', 'pedigree', 'mongrel', 'pep'],\n",
       " ['impeccable', 'pedigree', 'mongrel', 'pep'],\n",
       " ['impeccable', 'pedigree', 'mongrel', 'pep'],\n",
       " ['impeccable', 'pedigree', 'mongrel', 'pep'],\n",
       " ['impeccable'],\n",
       " ['pedigree', 'mongrel', 'pep'],\n",
       " ['pedigree'],\n",
       " ['mongrel', 'pep'],\n",
       " ['mongrel', 'pep'],\n",
       " ['mongrel'],\n",
       " ['pep'],\n",
       " ['almost'],\n",
       " ['indecipherable', 'plot', 'complications'],\n",
       " ['indecipherable'],\n",
       " ['plot', 'complications'],\n",
       " ['complications'],\n",
       " ['film', 'clearly', 'means', 'preach', 'exclusively', 'converted'],\n",
       " ['film', 'clearly', 'means'],\n",
       " ['film'],\n",
       " ['clearly', 'means'],\n",
       " ['clearly', 'means'],\n",
       " ['clearly'],\n",
       " ['means'],\n",
       " ['means'],\n",
       " ['preach', 'exclusively', 'converted'],\n",
       " ['preach', 'exclusively', 'converted'],\n",
       " ['preach', 'exclusively'],\n",
       " ['preach'],\n",
       " ['exclusively'],\n",
       " ['converted'],\n",
       " ['converted'],\n",
       " ['converted'],\n",
       " ['importance',\n",
       "  'earnest',\n",
       "  'offers',\n",
       "  'opportunities',\n",
       "  'occasional',\n",
       "  'smiles',\n",
       "  'chuckles',\n",
       "  'nt',\n",
       "  'give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['importance',\n",
       "  'earnest',\n",
       "  'offers',\n",
       "  'opportunities',\n",
       "  'occasional',\n",
       "  'smiles',\n",
       "  'chuckles'],\n",
       " ['importance',\n",
       "  'earnest',\n",
       "  'offers',\n",
       "  'opportunities',\n",
       "  'occasional',\n",
       "  'smiles',\n",
       "  'chuckles'],\n",
       " ['importance', 'earnest'],\n",
       " ['earnest'],\n",
       " ['earnest'],\n",
       " ['offers', 'opportunities', 'occasional', 'smiles', 'chuckles'],\n",
       " ['offers', 'opportunities', 'occasional', 'smiles'],\n",
       " ['offers', 'opportunities', 'occasional', 'smiles'],\n",
       " ['offers'],\n",
       " ['opportunities', 'occasional', 'smiles'],\n",
       " ['opportunities'],\n",
       " ['occasional', 'smiles'],\n",
       " ['occasional', 'smiles'],\n",
       " ['occasional'],\n",
       " ['smiles'],\n",
       " ['chuckles'],\n",
       " ['nt',\n",
       "  'give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['nt',\n",
       "  'give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['nt',\n",
       "  'give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['nt',\n",
       "  'give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['give',\n",
       "  'us',\n",
       "  'reason',\n",
       "  'theater',\n",
       "  'beyond',\n",
       "  'wilde',\n",
       "  'wit',\n",
       "  'actors',\n",
       "  'performances'],\n",
       " ['give', 'us'],\n",
       " ['give'],\n",
       " ['reason', 'theater', 'beyond', 'wilde', 'wit', 'actors', 'performances'],\n",
       " ['reason', 'theater', 'beyond', 'wilde', 'wit', 'actors', 'performances'],\n",
       " ['theater', 'beyond', 'wilde', 'wit', 'actors', 'performances'],\n",
       " ['theater', 'beyond', 'wilde', 'wit', 'actors', 'performances'],\n",
       " ['theater'],\n",
       " ['theater'],\n",
       " ['theater'],\n",
       " ['theater'],\n",
       " ['beyond', 'wilde', 'wit', 'actors', 'performances'],\n",
       " ['beyond'],\n",
       " ['wilde', 'wit', 'actors', 'performances'],\n",
       " ['wilde', 'wit'],\n",
       " ['wilde', 'wit'],\n",
       " ['wilde'],\n",
       " ['wilde'],\n",
       " ['actors', 'performances'],\n",
       " ['actors'],\n",
       " ['actors'],\n",
       " ['actors'],\n",
       " ['latest',\n",
       "  'vapid',\n",
       "  'actor',\n",
       "  'exercise',\n",
       "  'appropriate',\n",
       "  'structure',\n",
       "  'arthur',\n",
       "  'schnitzler',\n",
       "  'reigen'],\n",
       " ['latest'],\n",
       " ['latest'],\n",
       " ['vapid',\n",
       "  'actor',\n",
       "  'exercise',\n",
       "  'appropriate',\n",
       "  'structure',\n",
       "  'arthur',\n",
       "  'schnitzler',\n",
       "  'reigen'],\n",
       " ['vapid',\n",
       "  'actor',\n",
       "  'exercise',\n",
       "  'appropriate',\n",
       "  'structure',\n",
       "  'arthur',\n",
       "  'schnitzler',\n",
       "  'reigen'],\n",
       " ['vapid', 'actor', 'exercise'],\n",
       " ['vapid'],\n",
       " ['actor', 'exercise'],\n",
       " ['actor'],\n",
       " ['actor'],\n",
       " ['exercise'],\n",
       " ['appropriate', 'structure', 'arthur', 'schnitzler', 'reigen'],\n",
       " ['appropriate', 'structure', 'arthur', 'schnitzler', 'reigen'],\n",
       " ['appropriate', 'structure'],\n",
       " ['appropriate'],\n",
       " ['structure'],\n",
       " ['structure'],\n",
       " ['arthur', 'schnitzler', 'reigen'],\n",
       " ['arthur', 'schnitzler', 'reigen'],\n",
       " ['arthur', 'schnitzler'],\n",
       " ['arthur'],\n",
       " ['schnitzler'],\n",
       " ['schnitzler'],\n",
       " ['reigen'],\n",
       " ['vaudeville',\n",
       "  'show',\n",
       "  'wellconstructed',\n",
       "  'narrative',\n",
       "  'terms',\n",
       "  'inoffensive',\n",
       "  'actually',\n",
       "  'rather',\n",
       "  'sweet'],\n",
       " ['vaudeville',\n",
       "  'show',\n",
       "  'wellconstructed',\n",
       "  'narrative',\n",
       "  'terms',\n",
       "  'inoffensive',\n",
       "  'actually',\n",
       "  'rather',\n",
       "  'sweet'],\n",
       " ['vaudeville', 'show', 'wellconstructed', 'narrative'],\n",
       " ['vaudeville', 'show', 'wellconstructed', 'narrative'],\n",
       " ['vaudeville', 'show', 'wellconstructed', 'narrative'],\n",
       " ['vaudeville'],\n",
       " ['vaudeville'],\n",
       " ['show', 'wellconstructed', 'narrative'],\n",
       " ['show'],\n",
       " ['wellconstructed', 'narrative'],\n",
       " ['wellconstructed', 'narrative'],\n",
       " ['wellconstructed'],\n",
       " ['narrative'],\n",
       " ['terms', 'inoffensive', 'actually', 'rather', 'sweet'],\n",
       " ['terms'],\n",
       " ['terms'],\n",
       " ['terms'],\n",
       " ['inoffensive', 'actually', 'rather', 'sweet'],\n",
       " ['inoffensive', 'actually', 'rather', 'sweet'],\n",
       " ['inoffensive', 'actually', 'rather', 'sweet'],\n",
       " ['inoffensive', 'actually'],\n",
       " ['inoffensive'],\n",
       " ['inoffensive'],\n",
       " ['actually'],\n",
       " ['rather', 'sweet'],\n",
       " ['rather'],\n",
       " ['nothing', 'runofthemill', 'action', 'flick'],\n",
       " ['runofthemill', 'action', 'flick'],\n",
       " ['runofthemill', 'action'],\n",
       " ['runofthemill', 'action'],\n",
       " ['runofthemill', 'action'],\n",
       " ['runofthemill', 'action'],\n",
       " ['runofthemill'],\n",
       " ['action'],\n",
       " ['flick'],\n",
       " ['hampered',\n",
       "  'paralyzed',\n",
       "  'selfindulgent',\n",
       "  'script',\n",
       "  'aims',\n",
       "  'poetry',\n",
       "  'ends',\n",
       "  'sounding',\n",
       "  'like',\n",
       "  'satire'],\n",
       " ['hampered',\n",
       "  'paralyzed',\n",
       "  'selfindulgent',\n",
       "  'script',\n",
       "  'aims',\n",
       "  'poetry',\n",
       "  'ends',\n",
       "  'sounding',\n",
       "  'like',\n",
       "  'satire'],\n",
       " ['hampered', 'paralyzed', 'selfindulgent', 'script'],\n",
       " ['hampered', 'paralyzed', 'selfindulgent', 'script'],\n",
       " ['hampered', 'paralyzed'],\n",
       " ['hampered'],\n",
       " ['paralyzed'],\n",
       " ['paralyzed'],\n",
       " ['paralyzed'],\n",
       " ['paralyzed'],\n",
       " ['paralyzed'],\n",
       " ['selfindulgent', 'script'],\n",
       " ['selfindulgent', 'script'],\n",
       " ['selfindulgent', 'script'],\n",
       " ['selfindulgent'],\n",
       " ['script'],\n",
       " ['aims', 'poetry', 'ends', 'sounding', 'like', 'satire'],\n",
       " ['aims', 'poetry', 'ends', 'sounding', 'like', 'satire'],\n",
       " ['aims', 'poetry'],\n",
       " ['aims', 'poetry'],\n",
       " ['aims'],\n",
       " ['poetry'],\n",
       " ['poetry'],\n",
       " ['ends', 'sounding', 'like', 'satire'],\n",
       " ['ends'],\n",
       " ['ends'],\n",
       " ['sounding', 'like', 'satire'],\n",
       " ['sounding'],\n",
       " ['like', 'satire'],\n",
       " ['satire'],\n",
       " ['ice',\n",
       "  'age',\n",
       "  'first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies',\n",
       "  'makes',\n",
       "  'glacial',\n",
       "  'pacing',\n",
       "  'early'],\n",
       " ['ice',\n",
       "  'age',\n",
       "  'first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies',\n",
       "  'makes',\n",
       "  'glacial',\n",
       "  'pacing',\n",
       "  'early'],\n",
       " ['ice',\n",
       "  'age',\n",
       "  'first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies'],\n",
       " ['ice',\n",
       "  'age',\n",
       "  'first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies'],\n",
       " ['ice',\n",
       "  'age',\n",
       "  'first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies'],\n",
       " ['ice', 'age'],\n",
       " ['ice'],\n",
       " ['age'],\n",
       " ['first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies'],\n",
       " ['first',\n",
       "  'computergenerated',\n",
       "  'feature',\n",
       "  'cartoon',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'movies'],\n",
       " ['first', 'computergenerated', 'feature', 'cartoon'],\n",
       " ['first', 'computergenerated', 'feature', 'cartoon'],\n",
       " ['first'],\n",
       " ['computergenerated', 'feature', 'cartoon'],\n",
       " ['computergenerated'],\n",
       " ['feature', 'cartoon'],\n",
       " ['feature'],\n",
       " ['cartoon'],\n",
       " ['feel', 'like', 'movies'],\n",
       " ['feel', 'like', 'movies'],\n",
       " ['feel'],\n",
       " ['like', 'movies'],\n",
       " ['movies'],\n",
       " ['makes', 'glacial', 'pacing', 'early'],\n",
       " ['makes', 'glacial', 'pacing', 'early'],\n",
       " ['makes', 'glacial', 'pacing'],\n",
       " ['makes'],\n",
       " ['glacial', 'pacing'],\n",
       " ['glacial', 'pacing'],\n",
       " ['glacial', 'pacing'],\n",
       " ['glacial'],\n",
       " ['pacing'],\n",
       " ['early'],\n",
       " ['early'],\n",
       " ['little',\n",
       "  'sense',\n",
       "  'going',\n",
       "  'makers',\n",
       "  'serve',\n",
       "  'cliches',\n",
       "  'considerable',\n",
       "  'dash'],\n",
       " ['little',\n",
       "  'sense',\n",
       "  'going',\n",
       "  'makers',\n",
       "  'serve',\n",
       "  'cliches',\n",
       "  'considerable',\n",
       "  'dash'],\n",
       " ['little', 'sense', 'going'],\n",
       " ['little', 'sense', 'going'],\n",
       " ['little', 'sense', 'going'],\n",
       " ['little', 'sense', 'going'],\n",
       " ['little', 'sense', 'going'],\n",
       " ['little', 'sense'],\n",
       " ['little'],\n",
       " ['going'],\n",
       " ['going'],\n",
       " ['going'],\n",
       " ['going'],\n",
       " ['going'],\n",
       " ['makers', 'serve', 'cliches', 'considerable', 'dash'],\n",
       " ['makers'],\n",
       " ['makers'],\n",
       " ['serve', 'cliches', 'considerable', 'dash'],\n",
       " ['serve'],\n",
       " ['serve'],\n",
       " ['cliches', 'considerable', 'dash'],\n",
       " ['cliches'],\n",
       " ['cliches'],\n",
       " ['considerable', 'dash'],\n",
       " ['considerable', 'dash'],\n",
       " ['considerable'],\n",
       " ['dash'],\n",
       " ['cattaneo',\n",
       "  'followed',\n",
       "  'runaway',\n",
       "  'success',\n",
       "  'first',\n",
       "  'film',\n",
       "  'full',\n",
       "  'monty',\n",
       "  'something',\n",
       "  'different'],\n",
       " ['cattaneo'],\n",
       " ['followed',\n",
       "  'runaway',\n",
       "  'success',\n",
       "  'first',\n",
       "  'film',\n",
       "  'full',\n",
       "  'monty',\n",
       "  'something',\n",
       "  'different'],\n",
       " ['followed',\n",
       "  'runaway',\n",
       "  'success',\n",
       "  'first',\n",
       "  'film',\n",
       "  'full',\n",
       "  'monty',\n",
       "  'something',\n",
       "  'different'],\n",
       " ['followed',\n",
       "  'runaway',\n",
       "  'success',\n",
       "  'first',\n",
       "  'film',\n",
       "  'full',\n",
       "  'monty',\n",
       "  'something',\n",
       "  'different'],\n",
       " ['followed',\n",
       "  'runaway',\n",
       "  'success',\n",
       "  'first',\n",
       "  'film',\n",
       "  'full',\n",
       "  'monty',\n",
       "  'something',\n",
       "  'different'],\n",
       " ['followed', 'runaway', 'success', 'first', 'film', 'full', 'monty'],\n",
       " ['followed'],\n",
       " ['runaway', 'success', 'first', 'film', 'full', 'monty'],\n",
       " ['runaway', 'success'],\n",
       " ['runaway', 'success'],\n",
       " ['runaway'],\n",
       " ['success'],\n",
       " ['first', 'film', 'full', 'monty'],\n",
       " ['first', 'film', 'full', 'monty'],\n",
       " ['first', 'film', 'full', 'monty'],\n",
       " ['first', 'film'],\n",
       " ['first', 'film'],\n",
       " ['first', 'film'],\n",
       " ['full', 'monty'],\n",
       " ['full', 'monty'],\n",
       " ['full'],\n",
       " ['monty'],\n",
       " ['something', 'different'],\n",
       " ['something', 'different'],\n",
       " ['different'],\n",
       " ['unnamed',\n",
       "  'easily',\n",
       "  'substitutable',\n",
       "  'forces',\n",
       "  'serve',\n",
       "  'whatever',\n",
       "  'terror',\n",
       "  'heroes',\n",
       "  'horror',\n",
       "  'movies',\n",
       "  'try',\n",
       "  'avoid'],\n",
       " ['unnamed',\n",
       "  'easily',\n",
       "  'substitutable',\n",
       "  'forces',\n",
       "  'serve',\n",
       "  'whatever',\n",
       "  'terror',\n",
       "  'heroes',\n",
       "  'horror',\n",
       "  'movies',\n",
       "  'try',\n",
       "  'avoid'],\n",
       " ['unnamed',\n",
       "  'easily',\n",
       "  'substitutable',\n",
       "  'forces',\n",
       "  'serve',\n",
       "  'whatever',\n",
       "  'terror',\n",
       "  'heroes',\n",
       "  'horror',\n",
       "  'movies',\n",
       "  'try',\n",
       "  'avoid'],\n",
       " ['unnamed',\n",
       "  'easily',\n",
       "  'substitutable',\n",
       "  'forces',\n",
       "  'serve',\n",
       "  'whatever',\n",
       "  'terror',\n",
       "  'heroes',\n",
       "  'horror',\n",
       "  'movies',\n",
       "  'try',\n",
       "  'avoid'],\n",
       " ['unnamed', 'easily', 'substitutable', 'forces'],\n",
       " ['unnamed', 'easily', 'substitutable', 'forces'],\n",
       " ['unnamed', 'easily', 'substitutable'],\n",
       " ['unnamed'],\n",
       " ['easily', 'substitutable'],\n",
       " ['easily', 'substitutable'],\n",
       " ['easily'],\n",
       " ['substitutable'],\n",
       " ['forces'],\n",
       " ['serve', 'whatever', 'terror', 'heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['serve', 'whatever', 'terror', 'heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['whatever', 'terror', 'heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['whatever', 'terror', 'heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['whatever'],\n",
       " ['terror', 'heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['terror'],\n",
       " ['heroes', 'horror', 'movies', 'try', 'avoid'],\n",
       " ['heroes', 'horror', 'movies'],\n",
       " ['heroes'],\n",
       " ['heroes'],\n",
       " ['horror', 'movies'],\n",
       " ['horror', 'movies'],\n",
       " ['horror'],\n",
       " ['try', 'avoid'],\n",
       " ['avoid'],\n",
       " ['avoid'],\n",
       " ['almost', 'feels', 'movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['almost', 'feels', 'movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['feels', 'movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['feels', 'movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['feels'],\n",
       " ['movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['movie', 'interested', 'entertaining', 'amusing', 'us'],\n",
       " ['interested', 'entertaining', 'amusing', 'us'],\n",
       " ['interested', 'entertaining', 'amusing', 'us'],\n",
       " ['interested', 'entertaining'],\n",
       " ['interested', 'entertaining'],\n",
       " ['interested'],\n",
       " ['entertaining'],\n",
       " ['entertaining'],\n",
       " ['amusing', 'us'],\n",
       " ['amusing', 'us'],\n",
       " ['amusing', 'us'],\n",
       " ['amusing'],\n",
       " ['movie',\n",
       "  'progression',\n",
       "  'rambling',\n",
       "  'incoherence',\n",
       "  'gives',\n",
       "  'new',\n",
       "  'meaning',\n",
       "  'phrase',\n",
       "  'fatal',\n",
       "  'script',\n",
       "  'error'],\n",
       " ['movie', 'progression', 'rambling', 'incoherence'],\n",
       " ['movie', 'progression'],\n",
       " ['progression'],\n",
       " ['rambling', 'incoherence'],\n",
       " ['rambling', 'incoherence'],\n",
       " ['rambling'],\n",
       " ['incoherence'],\n",
       " ['gives', 'new', 'meaning', 'phrase', 'fatal', 'script', 'error'],\n",
       " ['gives', 'new', 'meaning', 'phrase', 'fatal', 'script', 'error'],\n",
       " ['gives', 'new', 'meaning', 'phrase', 'fatal', 'script', 'error'],\n",
       " ['gives', 'new', 'meaning'],\n",
       " ['gives'],\n",
       " ['new', 'meaning'],\n",
       " ['new'],\n",
       " ['meaning'],\n",
       " ['phrase', 'fatal', 'script', 'error'],\n",
       " ['phrase', 'fatal', 'script', 'error'],\n",
       " ['phrase', 'fatal', 'script', 'error'],\n",
       " ['phrase'],\n",
       " ['fatal', 'script', 'error'],\n",
       " ['fatal', 'script', 'error'],\n",
       " ['fatal'],\n",
       " ['script', 'error'],\n",
       " ['error'],\n",
       " ['nt',\n",
       "  'judge',\n",
       "  'one',\n",
       "  'soon',\n",
       "  'dark',\n",
       "  'gritty',\n",
       "  'story',\n",
       "  'takes',\n",
       "  'totally',\n",
       "  'unexpected',\n",
       "  'directions',\n",
       "  'keeps',\n",
       "  'going'],\n",
       " ['nt',\n",
       "  'judge',\n",
       "  'one',\n",
       "  'soon',\n",
       "  'dark',\n",
       "  'gritty',\n",
       "  'story',\n",
       "  'takes',\n",
       "  'totally',\n",
       "  'unexpected',\n",
       "  'directions',\n",
       "  'keeps',\n",
       "  'going'],\n",
       " ['nt', 'judge', 'one', 'soon'],\n",
       " ['nt', 'judge', 'one', 'soon'],\n",
       " ['nt'],\n",
       " ['judge', 'one', 'soon'],\n",
       " ['judge', 'one'],\n",
       " ['judge'],\n",
       " ['soon'],\n",
       " ['soon'],\n",
       " ['dark',\n",
       "  'gritty',\n",
       "  'story',\n",
       "  'takes',\n",
       "  'totally',\n",
       "  'unexpected',\n",
       "  'directions',\n",
       "  'keeps',\n",
       "  'going'],\n",
       " ['dark', 'gritty', 'story'],\n",
       " ['dark', 'gritty', 'story'],\n",
       " ['dark', 'gritty', 'story'],\n",
       " ['dark', 'gritty', 'story'],\n",
       " ['dark', 'gritty', 'story'],\n",
       " ['dark'],\n",
       " ['gritty', 'story'],\n",
       " ['gritty', 'story'],\n",
       " ['gritty'],\n",
       " ['takes', 'totally', 'unexpected', 'directions', 'keeps', 'going'],\n",
       " ['takes', 'totally', 'unexpected', 'directions', 'keeps', 'going'],\n",
       " ['takes', 'totally', 'unexpected', 'directions'],\n",
       " ['takes', 'totally', 'unexpected', 'directions'],\n",
       " ['takes'],\n",
       " ['takes'],\n",
       " ['totally', 'unexpected', 'directions'],\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b58c04f5-4598-407d-989f-e98e618e7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, vector_size=100, window=5, min_count=2, epochs=30, sg=1, negative=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e565101e-7335-4544-834d-378d7481537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_w2v(tokens, model, vector_size=100):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv.key_to_index:\n",
    "            vectors.append(model.wv[token])\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a89a8a94-5778-41b3-8919-3df9816ff060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['w2v_vector'] = train_df['Phrase_tokens_filtered'].apply(lambda x: text_to_w2v(x, model, vector_size=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "577d0780-60f2-44d0-8242-1fb4e50987b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Phrase_clean</th>\n",
       "      <th>Phrase_tokens</th>\n",
       "      <th>Phrase_tokens_filtered</th>\n",
       "      <th>text_for_tfidf</th>\n",
       "      <th>w2v_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>series escapades demonstrating adage good goos...</td>\n",
       "      <td>[-0.30980554, 0.87488675, 0.039591227, 0.02845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>a series of escapades demonstrating the adage ...</td>\n",
       "      <td>[a, series, of, escapades, demonstrating, the,...</td>\n",
       "      <td>[series, escapades, demonstrating, adage, good...</td>\n",
       "      <td>series escapades demonstrating adage good goose</td>\n",
       "      <td>[-0.15568924, 0.70437956, -0.16359217, -0.0987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>a series</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>[series]</td>\n",
       "      <td>series</td>\n",
       "      <td>[0.22660993, 0.7875314, -0.3691682, -0.6059792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>[a]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "      <td>[series]</td>\n",
       "      <td>[series]</td>\n",
       "      <td>series</td>\n",
       "      <td>[0.22660993, 0.7875314, -0.3691682, -0.6059792...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>hearst s</td>\n",
       "      <td>[hearst, s]</td>\n",
       "      <td>[hearst]</td>\n",
       "      <td>hearst</td>\n",
       "      <td>[-0.5132919, 0.40002233, 0.14662139, -0.811359...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "      <td>[forced, avuncular, chortles]</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>[0.059204053, 0.87251616, 0.44474483, -0.10488...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "      <td>[avuncular, chortles]</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>[-0.17724614, 0.53292805, 0.37360215, -0.19694...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>[avuncular]</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>[-0.20767456, 0.5311063, 0.39184892, -0.172101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>chortles</td>\n",
       "      <td>[chortles]</td>\n",
       "      <td>[chortles]</td>\n",
       "      <td>chortles</td>\n",
       "      <td>[-0.14681771, 0.5347498, 0.35535538, -0.221780...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "                                             Phrase_clean  \\\n",
       "0       a series of escapades demonstrating the adage ...   \n",
       "1       a series of escapades demonstrating the adage ...   \n",
       "2                                                a series   \n",
       "3                                                       a   \n",
       "4                                                  series   \n",
       "...                                                   ...   \n",
       "156055                                           hearst s   \n",
       "156056                          forced avuncular chortles   \n",
       "156057                                 avuncular chortles   \n",
       "156058                                          avuncular   \n",
       "156059                                           chortles   \n",
       "\n",
       "                                            Phrase_tokens  \\\n",
       "0       [a, series, of, escapades, demonstrating, the,...   \n",
       "1       [a, series, of, escapades, demonstrating, the,...   \n",
       "2                                             [a, series]   \n",
       "3                                                     [a]   \n",
       "4                                                [series]   \n",
       "...                                                   ...   \n",
       "156055                                        [hearst, s]   \n",
       "156056                      [forced, avuncular, chortles]   \n",
       "156057                              [avuncular, chortles]   \n",
       "156058                                        [avuncular]   \n",
       "156059                                         [chortles]   \n",
       "\n",
       "                                   Phrase_tokens_filtered  \\\n",
       "0       [series, escapades, demonstrating, adage, good...   \n",
       "1       [series, escapades, demonstrating, adage, good...   \n",
       "2                                                [series]   \n",
       "3                                                      []   \n",
       "4                                                [series]   \n",
       "...                                                   ...   \n",
       "156055                                           [hearst]   \n",
       "156056                      [forced, avuncular, chortles]   \n",
       "156057                              [avuncular, chortles]   \n",
       "156058                                        [avuncular]   \n",
       "156059                                         [chortles]   \n",
       "\n",
       "                                           text_for_tfidf  \\\n",
       "0       series escapades demonstrating adage good goos...   \n",
       "1         series escapades demonstrating adage good goose   \n",
       "2                                                  series   \n",
       "3                                                           \n",
       "4                                                  series   \n",
       "...                                                   ...   \n",
       "156055                                             hearst   \n",
       "156056                          forced avuncular chortles   \n",
       "156057                                 avuncular chortles   \n",
       "156058                                          avuncular   \n",
       "156059                                           chortles   \n",
       "\n",
       "                                               w2v_vector  \n",
       "0       [-0.30980554, 0.87488675, 0.039591227, 0.02845...  \n",
       "1       [-0.15568924, 0.70437956, -0.16359217, -0.0987...  \n",
       "2       [0.22660993, 0.7875314, -0.3691682, -0.6059792...  \n",
       "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4       [0.22660993, 0.7875314, -0.3691682, -0.6059792...  \n",
       "...                                                   ...  \n",
       "156055  [-0.5132919, 0.40002233, 0.14662139, -0.811359...  \n",
       "156056  [0.059204053, 0.87251616, 0.44474483, -0.10488...  \n",
       "156057  [-0.17724614, 0.53292805, 0.37360215, -0.19694...  \n",
       "156058  [-0.20767456, 0.5311063, 0.39184892, -0.172101...  \n",
       "156059  [-0.14681771, 0.5347498, 0.35535538, -0.221780...  \n",
       "\n",
       "[156060 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b36264a-3c78-4026-9e97-f7d6459859b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(train_df['w2v_vector'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9cdf954-9cdc-4cc1-9aa8-cd4347aa8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2625cfc3-a2bd-4c5e-918b-eae50cf0779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(train_df['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46b38df5-f07b-4cb6-829d-503925a0a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e1dd57f-c489-4b3d-9e4a-bc9d5178698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc6321f8-b36c-41d7-9178-d4aaae0afdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "386f28bf-1dd3-4ef5-9bae-286d6a52b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357af336-11cf-4405-8b6e-10fd8726277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-intro",
   "metadata": {},
   "source": [
    "## LSTM 模型构建\n",
    "\n",
    "在前面已完成文本清洗、分词、Word2Vec 向量化的基础上，这里使用 **双向 LSTM（BiLSTM）** 对文本序列直接建模，相比聚合词向量的 SVM，LSTM 能更好地捕捉词序和上下文依赖关系。\n",
    "\n",
    "流程：`Phrase_clean` → Tokenizer/Padding → Embedding → BiLSTM × 2 → Dense → Softmax(5类)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── LSTM 所需依赖 ──────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(f'TensorFlow 版本: {tf.__version__}')\n",
    "print(f'GPU 可用: {tf.config.list_physical_devices(\"GPU\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-data-prep-md",
   "metadata": {},
   "source": [
    "### 1. 数据准备 —— 文本序列化\n",
    "\n",
    "LSTM 直接处理词序列，因此用 Keras `Tokenizer` 将文本转换为整数索引，再进行 Padding 对齐长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-hyperparams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 超参数配置 ─────────────────────────────────────────────\n",
    "MAX_WORDS   = 20000   # 词典大小（保留最高频的 N 个词）\n",
    "MAX_LEN     = 50      # 序列最大长度（影评短语通常不超过 50 词）\n",
    "EMBED_DIM   = 128     # Embedding 向量维度\n",
    "LSTM_UNITS  = 128     # LSTM 隐层单元数\n",
    "DROPOUT     = 0.3     # Dropout 比例\n",
    "BATCH_SIZE  = 256\n",
    "EPOCHS      = 15\n",
    "NUM_CLASSES = 5       # 情感类别数：0(neg) ~ 4(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-tokenize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 文本序列化 ─────────────────────────────────────────────\n",
    "texts  = train_df['Phrase_clean'].fillna('').values\n",
    "labels = train_df['Sentiment'].values   # 原始标签 0~4\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X_seq = pad_sequences(sequences, maxlen=MAX_LEN,\n",
    "                      padding='post', truncating='post')\n",
    "\n",
    "print(f'词表实际大小   : {len(tokenizer.word_index)}')\n",
    "print(f'输入矩阵形状   : {X_seq.shape}')\n",
    "print(f'标签分布:\\n{pd.Series(labels).value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 划分训练 / 验证集 ─────────────────────────────────────\n",
    "y_cat = to_categorical(labels, num_classes=NUM_CLASSES)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_seq, y_cat,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels        # 保持各类比例\n",
    ")\n",
    "print(f'训练集 shape: {X_tr.shape}')\n",
    "print(f'验证集 shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-model-md",
   "metadata": {},
   "source": [
    "### 2. 构建双向 LSTM 模型\n",
    "\n",
    "结构：`Embedding → BiLSTM(128) → BiLSTM(64) → Dense(64, ReLU) → Dropout → Dense(5, Softmax)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm(vocab_size, embed_dim, lstm_units, max_len,\n",
    "                 num_classes, dropout):\n",
    "    \"\"\"\n",
    "    双向 LSTM 情感分类模型\n",
    "    - 两层堆叠 BiLSTM，第一层 return_sequences=True\n",
    "    - 全连接头 + Softmax 输出 5 个类别概率\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        # 1. Embedding 层：将词索引映射为稠密向量\n",
    "        Embedding(input_dim=vocab_size,\n",
    "                  output_dim=embed_dim,\n",
    "                  input_length=max_len,\n",
    "                  name='embedding'),\n",
    "\n",
    "        # 2. 第一层 BiLSTM（返回全序列供第二层使用）\n",
    "        Bidirectional(\n",
    "            LSTM(lstm_units,\n",
    "                 return_sequences=True,\n",
    "                 dropout=dropout,\n",
    "                 recurrent_dropout=0.1),\n",
    "            name='bilstm_1'\n",
    "        ),\n",
    "\n",
    "        # 3. 第二层 BiLSTM（输出最终隐状态）\n",
    "        Bidirectional(\n",
    "            LSTM(lstm_units // 2,\n",
    "                 dropout=dropout,\n",
    "                 recurrent_dropout=0.1),\n",
    "            name='bilstm_2'\n",
    "        ),\n",
    "\n",
    "        # 4. 全连接分类头\n",
    "        Dense(64, activation='relu', name='fc'),\n",
    "        Dropout(dropout),\n",
    "        Dense(num_classes, activation='softmax', name='output')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_bilstm(\n",
    "    vocab_size  = MAX_WORDS + 1,   # +1 为 OOV token 留位\n",
    "    embed_dim   = EMBED_DIM,\n",
    "    lstm_units  = LSTM_UNITS,\n",
    "    max_len     = MAX_LEN,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    dropout     = DROPOUT\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-train-md",
   "metadata": {},
   "source": [
    "### 3. 模型训练\n",
    "\n",
    "- **EarlyStopping**：监控验证集 Accuracy，连续 3 轮无提升则停止并恢复最佳权重  \n",
    "- **ReduceLROnPlateau**：验证集 Loss 连续 2 轮无下降则学习率减半"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-5,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_tr, y_tr,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-plot-md",
   "metadata": {},
   "source": [
    "### 4. 训练曲线可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss 曲线\n",
    "axes[0].plot(history.history['loss'],\n",
    "             label='Train Loss', linewidth=2, color='steelblue')\n",
    "axes[0].plot(history.history['val_loss'],\n",
    "             label='Val Loss', linewidth=2, linestyle='--', color='tomato')\n",
    "axes[0].set_title('Loss Curve', fontsize=14)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy 曲线\n",
    "axes[1].plot(history.history['accuracy'],\n",
    "             label='Train Acc', linewidth=2, color='steelblue')\n",
    "axes[1].plot(history.history['val_accuracy'],\n",
    "             label='Val Acc', linewidth=2, linestyle='--', color='tomato')\n",
    "axes[1].set_title('Accuracy Curve', fontsize=14)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('BiLSTM — Training History', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_training_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('图像已保存至 lstm_training_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-eval-md",
   "metadata": {},
   "source": [
    "### 5. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-eval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 整体指标 ──────────────────────────────────────────────\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f'验证集 Loss    : {val_loss:.4f}')\n",
    "print(f'验证集 Accuracy: {val_acc:.4f}\\n')\n",
    "\n",
    "# ── 各类别分类报告 ────────────────────────────────────────\n",
    "y_pred_prob = model.predict(X_val, batch_size=512, verbose=0)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "sentiment_labels = ['0-Negative', '1-Somewhat Neg', '2-Neutral',\n",
    "                    '3-Somewhat Pos', '4-Positive']\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=sentiment_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-confusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sentiment_labels,\n",
    "            yticklabels=sentiment_labels)\n",
    "plt.title('Confusion Matrix — BiLSTM', fontsize=14)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lstm_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('混淆矩阵已保存至 lstm_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-predict-md",
   "metadata": {},
   "source": [
    "### 6. 推理示例 —— 预测新文本情感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def predict_sentiment(texts_input, model, tokenizer, max_len=MAX_LEN):\n",
    "    \"\"\"\n",
    "    对任意文本列表进行情感预测。\n",
    "    返回 DataFrame，含文本、预测标签和置信度。\n",
    "    \"\"\"\n",
    "    # 与训练时一致的清洗\n",
    "    cleaned = [\n",
    "        t.translate(str.maketrans('', '', string.punctuation)).lower().strip()\n",
    "        for t in texts_input\n",
    "    ]\n",
    "    seqs   = tokenizer.texts_to_sequences(cleaned)\n",
    "    padded = pad_sequences(seqs, maxlen=max_len,\n",
    "                           padding='post', truncating='post')\n",
    "    probs  = model.predict(padded, verbose=0)\n",
    "    preds  = np.argmax(probs, axis=1)\n",
    "\n",
    "    label_map = {0: 'Negative', 1: 'Somewhat Neg', 2: 'Neutral',\n",
    "                 3: 'Somewhat Pos', 4: 'Positive'}\n",
    "\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            'text'      : text,\n",
    "            'sentiment' : label_map[preds[i]],\n",
    "            'label'     : int(preds[i]),\n",
    "            'confidence': round(float(probs[i, preds[i]]), 4)\n",
    "        }\n",
    "        for i, text in enumerate(texts_input)\n",
    "    ])\n",
    "\n",
    "\n",
    "# ── 示例推理 ──────────────────────────────────────────────\n",
    "demo_texts = [\n",
    "    'This movie is absolutely fantastic and deeply touching',\n",
    "    'Terrible film, complete waste of time',\n",
    "    'It was okay, nothing special',\n",
    "    'A masterpiece of storytelling and raw emotion',\n",
    "    'Boring and utterly predictable plot'\n",
    "]\n",
    "\n",
    "result_df = predict_sentiment(demo_texts, model, tokenizer)\n",
    "print(result_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm-save-md",
   "metadata": {},
   "source": [
    "### 7. 保存模型与 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存模型（Keras 原生格式）\n",
    "model.save('bilstm_sentiment_model.keras')\n",
    "print('模型已保存至 bilstm_sentiment_model.keras')\n",
    "\n",
    "# 保存 Tokenizer（推理时需要与训练时完全一致）\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "print('Tokenizer 已保存至 tokenizer.pkl')\n",
    "\n",
    "# ── 加载示例 ──────────────────────────────────────────────\n",
    "# loaded_model = tf.keras.models.load_model('bilstm_sentiment_model.keras')\n",
    "# with open('tokenizer.pkl', 'rb') as f:\n",
    "#     loaded_tokenizer = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}